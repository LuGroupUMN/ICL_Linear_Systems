# ICL_Linear_Systems
This project provides code for [In-Context Learning of Linear Systems: 
Generalization theory and Application to Operator Learning]


# Example 1: Linear system with random matrix
Consider the linear $Ax=y$, where 

- $A \in \mathbb{R}^{d \times d}$ is a $d$
 by $d$ matrix, that is defined by $A = QDQ^T$. Here $Q$ is a random random orthonormal matrix obtained from the QR decomposition of a random matrix. 
 
- Denote by $U_{d} \left[a,b\right]$ the distribution of $d \times d$ diagonal matrices with whose entries are independently sampled from the uniform distribution $U[a,b]$, that is $D \sim U_{d}\left[a,b\right]$ as $D= \text{diag} (\lambda_1,\dots,\lambda_{d}), ~
\lambda_i \overset{\mathrm{iid}}{\sim} U\left[a,b\right]$.

- The vector $y$ is sampled from a multivariate normal distribution $\mathcal{N}(0, \Sigma_d(\rho))$, where $\Sigma_d(\rho)$ denotes an equal-correlated covariance matrix, which is defined as $\Sigma_d(\rho) = (1-\rho)I_d + \rho F_d$, with $F_d\in \mathbb{R}^{d\times d}$ being a matrix of all ones.

## 1.1 Test the in-domain generalization
The procedures for evaluating error versus the number of tasks (N), length of prompts in training (n), and length of prompts during inference (m) follow the same setup.  
Here, we show the **generalization error versus the number of tasks (N)** as an example.

### 1.1.1 Generalization error vs. Number of Tasks (N)
- Navigate to the `RM/test_N` directory
- For evaluations w.r.t. prompt lengths:
  - Use `RM/test_sn` for training prompt length (n)
  - Use `RM/test_m` for inference prompt length (m)
- Modify configuration parameters in `config.py` as needed.

#### Step 1: Prepare the Data

```
python prepare_data.py
```


#### Step 2: Train the Model

```
python train.py
```
#### Step 3: Test the Model

```
python test.py
```

## 1.2 Test the out-of-domain (OOD) generalization with diversity
We evaluate the OOD generalization when trained on a **diverse** task distribution. Specifically, we expect the matrix $A$ to be diverse enough (See definition 3.3 in the paper).

- **Training:**, we sample $D \sim U_d \left[1,2\right]$ (**diverse**) and $y \sim N(0, I_d)$.
- **Task distribution shift At inference:** we vary the task distribution by varying $D \sim U_d \left[a,b\right]$ across various $(a,b)$.
- **Covariate shift at inference:** we vary the distribution of $y$ by varying $\rho$ in the covariance matrix $\Sigma(\rho)$.
### Navigate to the `RM/OOD` directory
#### Step 1: Prepare the Data

```
python prepare_data.py
```


#### Step 2: Train the Model

```
python train.py
```
#### Step 3: Test the generalization with 
* Task distribution shift
```
python test_V.py
```
* Covariate distribution shift
```
python test_f.py
```

## 1.3 Test the out-of-domain (OOD) generalization without diversity
We evaluate the OOD generalization when trained on a **non-diverse** task distribution.
- **Training:** we let $D = c I_d$, where $c \sim U \left[1,2\right]$ (**non-diverse**) and $y \sim N(0, I_d)$.
 - The training loss admits inifinitely many **bad** minimizers that do not generalize to downstream tasks, referred as **bad model**, while the one that generalizes is referred as the **optimal model**.
- **Covariate shift at inference:** we vary the task distribution by varying $D \sim U_d \left[a,b\right]$ across various $(a,b)$. And evaluate the OOD generalzation using two **bad model** and **optimal model**
### Navigate to the `RM/diversity` directory
#### Step 1: Prepare the Data

```
python prepare_data.py
```


#### Step 2: Train the Model

```
python train.py
```
#### Step 3: Test the OOD generalization with bad model and optimal model
```
python test.py
```

## 1.4 Plot
### Navigate to the `RM/` directory, Figure 1-3 are generated by running
```
plot_all_figs.ipynb
```
